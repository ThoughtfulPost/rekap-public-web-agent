// node_modules/@11labs/client/dist/lib.modern.js
function e() {
  return e = Object.assign ? Object.assign.bind() : function(e2) {
    for (var t2 = 1; t2 < arguments.length; t2++) {
      var n2 = arguments[t2];
      for (var a2 in n2) ({}).hasOwnProperty.call(n2, a2) && (e2[a2] = n2[a2]);
    }
    return e2;
  }, e.apply(null, arguments);
}
function t(e2) {
  const t2 = new Uint8Array(e2);
  return window.btoa(String.fromCharCode(...t2));
}
function n(e2) {
  const t2 = window.atob(e2), n2 = t2.length, a2 = new Uint8Array(n2);
  for (let e3 = 0; e3 < n2; e3++) a2[e3] = t2.charCodeAt(e3);
  return a2.buffer;
}
var a = new Blob([`
      const BIAS = 0x84;
      const CLIP = 32635;
      const encodeTable = [
        0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,
        4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,
        5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
        5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
        6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
        6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
        6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
        6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7
      ];
      
      function encodeSample(sample) {
        let sign;
        let exponent;
        let mantissa;
        let muLawSample;
        sign = (sample >> 8) & 0x80;
        if (sign !== 0) sample = -sample;
        sample = sample + BIAS;
        if (sample > CLIP) sample = CLIP;
        exponent = encodeTable[(sample>>7) & 0xFF];
        mantissa = (sample >> (exponent+3)) & 0x0F;
        muLawSample = ~(sign | (exponent << 4) | mantissa);
        
        return muLawSample;
      }
    
      class RawAudioProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
                    
          this.port.onmessage = ({ data }) => {
            this.buffer = []; // Initialize an empty buffer
            this.bufferSize = data.sampleRate / 4;
            
            if (globalThis.LibSampleRate && sampleRate !== data.sampleRate) {
              globalThis.LibSampleRate.create(1, sampleRate, data.sampleRate).then(resampler => {
                this.resampler = resampler;
              });
            } 
          };
        }
        process(inputs) {
          if (!this.buffer) {
            return true;
          }
          
          const input = inputs[0]; // Get the first input node
          if (input.length > 0) {
            let channelData = input[0]; // Get the first channel's data

            // Resample the audio if necessary
            if (this.resampler) {
              channelData = this.resampler.full(channelData);
            }

            // Add channel data to the buffer
            this.buffer.push(...channelData);
            // Get max volume 
            let sum = 0.0;
            for (let i = 0; i < channelData.length; i++) {
              sum += channelData[i] * channelData[i];
            }
            const maxVolume = Math.sqrt(sum / channelData.length);
            // Check if buffer size has reached or exceeded the threshold
            if (this.buffer.length >= this.bufferSize) {
              const float32Array = new Float32Array(this.buffer)
              let encodedArray = this.format === "ulaw"
                ? new Uint8Array(float32Array.length)
                : new Int16Array(float32Array.length);

              // Iterate through the Float32Array and convert each sample to PCM16
              for (let i = 0; i < float32Array.length; i++) {
                // Clamp the value to the range [-1, 1]
                let sample = Math.max(-1, Math.min(1, float32Array[i]));

                // Scale the sample to the range [-32768, 32767]
                let value = sample < 0 ? sample * 32768 : sample * 32767;
                if (this.format === "ulaw") {
                  value = encodeSample(Math.round(value));
                }

                encodedArray[i] = value;
              }

              // Send the buffered data to the main script
              this.port.postMessage([encodedArray, maxVolume]);

              // Clear the buffer after sending
              this.buffer = [];
            }
          }
          return true; // Continue processing
        }
      }
      registerProcessor("raw-audio-processor", RawAudioProcessor);
  `], { type: "application/javascript" });
var s = URL.createObjectURL(a);
var o = class _o {
  static async create({ sampleRate: e2, format: t2, preferHeadphonesForIosDevices: n2 }) {
    let a2 = null, i2 = null;
    try {
      const r3 = { sampleRate: { ideal: e2 }, echoCancellation: { ideal: true }, noiseSuppression: { ideal: true } }, l3 = await navigator.mediaDevices.getUserMedia({ audio: true });
      if (null == l3 || l3.getTracks().forEach((e3) => e3.stop()), (["iPad Simulator", "iPhone Simulator", "iPod Simulator", "iPad", "iPhone", "iPod"].includes(navigator.platform) || navigator.userAgent.includes("Mac") && "ontouchend" in document) && n2) {
        const e3 = (await window.navigator.mediaDevices.enumerateDevices()).find((e4) => "audioinput" === e4.kind && ["airpod", "headphone", "earphone"].find((t3) => e4.label.toLowerCase().includes(t3)));
        e3 && (r3.deviceId = { ideal: e3.deviceId });
      }
      const c2 = navigator.mediaDevices.getSupportedConstraints().sampleRate;
      a2 = new window.AudioContext(c2 ? { sampleRate: e2 } : {});
      const u2 = a2.createAnalyser();
      c2 || await a2.audioWorklet.addModule("https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js"), await a2.audioWorklet.addModule(s), i2 = await navigator.mediaDevices.getUserMedia({ audio: r3 });
      const d2 = a2.createMediaStreamSource(i2), p2 = new AudioWorkletNode(a2, "raw-audio-processor");
      return p2.port.postMessage({ type: "setFormat", format: t2, sampleRate: e2 }), d2.connect(u2), u2.connect(p2), new _o(a2, u2, p2, i2);
    } catch (e3) {
      var r2, l2;
      throw null == (r2 = i2) || r2.getTracks().forEach((e4) => e4.stop()), null == (l2 = a2) || l2.close(), e3;
    }
  }
  constructor(e2, t2, n2, a2) {
    this.context = void 0, this.analyser = void 0, this.worklet = void 0, this.inputStream = void 0, this.context = e2, this.analyser = t2, this.worklet = n2, this.inputStream = a2;
  }
  async close() {
    this.inputStream.getTracks().forEach((e2) => e2.stop()), await this.context.close();
  }
};
var i = new Blob(['\n      const decodeTable = [0,132,396,924,1980,4092,8316,16764];\n      \n      export function decodeSample(muLawSample) {\n        let sign;\n        let exponent;\n        let mantissa;\n        let sample;\n        muLawSample = ~muLawSample;\n        sign = (muLawSample & 0x80);\n        exponent = (muLawSample >> 4) & 0x07;\n        mantissa = muLawSample & 0x0F;\n        sample = decodeTable[exponent] + (mantissa << (exponent+3));\n        if (sign !== 0) sample = -sample;\n\n        return sample;\n      }\n      \n      class AudioConcatProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffers = []; // Initialize an empty buffer\n          this.cursor = 0;\n          this.currentBuffer = null;\n          this.wasInterrupted = false;\n          this.finished = false;\n          \n          this.port.onmessage = ({ data }) => {\n            switch (data.type) {\n              case "setFormat":\n                this.format = data.format;\n                break;\n              case "buffer":\n                this.wasInterrupted = false;\n                this.buffers.push(\n                  this.format === "ulaw"\n                    ? new Uint8Array(data.buffer)\n                    : new Int16Array(data.buffer)\n                );\n                break;\n              case "interrupt":\n                this.wasInterrupted = true;\n                break;\n              case "clearInterrupted":\n                if (this.wasInterrupted) {\n                  this.wasInterrupted = false;\n                  this.buffers = [];\n                  this.currentBuffer = null;\n                }\n            }\n          };\n        }\n        process(_, outputs) {\n          let finished = false;\n          const output = outputs[0][0];\n          for (let i = 0; i < output.length; i++) {\n            if (!this.currentBuffer) {\n              if (this.buffers.length === 0) {\n                finished = true;\n                break;\n              }\n              this.currentBuffer = this.buffers.shift();\n              this.cursor = 0;\n            }\n\n            let value = this.currentBuffer[this.cursor];\n            if (this.format === "ulaw") {\n              value = decodeSample(value);\n            }\n            output[i] = value / 32768;\n            this.cursor++;\n\n            if (this.cursor >= this.currentBuffer.length) {\n              this.currentBuffer = null;\n            }\n          }\n\n          if (this.finished !== finished) {\n            this.finished = finished;\n            this.port.postMessage({ type: "process", finished });\n          }\n\n          return true; // Continue processing\n        }\n      }\n\n      registerProcessor("audio-concat-processor", AudioConcatProcessor);\n    '], { type: "application/javascript" });
var r = URL.createObjectURL(i);
var l = class _l {
  static async create({ sampleRate: e2, format: t2 }) {
    let n2 = null;
    try {
      n2 = new AudioContext({ sampleRate: e2 });
      const a3 = n2.createAnalyser(), s2 = n2.createGain();
      s2.connect(a3), a3.connect(n2.destination), await n2.audioWorklet.addModule(r);
      const o2 = new AudioWorkletNode(n2, "audio-concat-processor");
      return o2.port.postMessage({ type: "setFormat", format: t2 }), o2.connect(s2), new _l(n2, a3, s2, o2);
    } catch (e3) {
      var a2;
      throw null == (a2 = n2) || a2.close(), e3;
    }
  }
  constructor(e2, t2, n2, a2) {
    this.context = void 0, this.analyser = void 0, this.gain = void 0, this.worklet = void 0, this.context = e2, this.analyser = t2, this.gain = n2, this.worklet = a2;
  }
  async close() {
    await this.context.close();
  }
};
function c(e2) {
  return !!e2.type;
}
var u = class _u {
  static async create(e2) {
    let t2 = null;
    try {
      var n2;
      const a3 = null != (n2 = e2.origin) ? n2 : "wss://api.elevenlabs.io", s2 = e2.signedUrl ? e2.signedUrl : a3 + "/v1/convai/conversation?agent_id=" + e2.agentId, o2 = ["convai"];
      e2.authorization && o2.push(`bearer.${e2.authorization}`), t2 = new WebSocket(s2, o2);
      const i2 = await new Promise((n3, a4) => {
        t2.addEventListener("open", () => {
          var n4;
          const a5 = { type: "conversation_initiation_client_data" };
          var s3, o3, i3, r3;
          e2.overrides && (a5.conversation_config_override = { agent: { prompt: null == (s3 = e2.overrides.agent) ? void 0 : s3.prompt, first_message: null == (o3 = e2.overrides.agent) ? void 0 : o3.firstMessage, language: null == (i3 = e2.overrides.agent) ? void 0 : i3.language }, tts: { voice_id: null == (r3 = e2.overrides.tts) ? void 0 : r3.voiceId } }), e2.customLlmExtraBody && (a5.custom_llm_extra_body = e2.customLlmExtraBody), e2.dynamicVariables && (a5.dynamic_variables = e2.dynamicVariables), null == (n4 = t2) || n4.send(JSON.stringify(a5));
        }, { once: true }), t2.addEventListener("error", a4), t2.addEventListener("close", a4), t2.addEventListener("message", (e3) => {
          const t3 = JSON.parse(e3.data);
          c(t3) && ("conversation_initiation_metadata" === t3.type ? n3(t3.conversation_initiation_metadata_event) : console.warn("First received message is not conversation metadata."));
        }, { once: true });
      }), { conversation_id: r2, agent_output_audio_format: l2, user_input_audio_format: p2 } = i2, h2 = d(null != p2 ? p2 : "pcm_16000"), m2 = d(l2);
      return new _u(t2, r2, h2, m2);
    } catch (e3) {
      var a2;
      throw null == (a2 = t2) || a2.close(), e3;
    }
  }
  constructor(e2, t2, n2, a2) {
    this.socket = void 0, this.conversationId = void 0, this.inputFormat = void 0, this.outputFormat = void 0, this.socket = e2, this.conversationId = t2, this.inputFormat = n2, this.outputFormat = a2;
  }
  close() {
    this.socket.close();
  }
  sendMessage(e2) {
    this.socket.send(JSON.stringify(e2));
  }
};
function d(e2) {
  const [t2, n2] = e2.split("_");
  if (!["pcm", "ulaw"].includes(t2)) throw new Error(`Invalid format: ${e2}`);
  const a2 = parseInt(n2);
  if (isNaN(a2)) throw new Error(`Invalid sample rate: ${n2}`);
  return { format: t2, sampleRate: a2 };
}
var p = { clientTools: {} };
var h = { onConnect: () => {
}, onDebug: () => {
}, onDisconnect: () => {
}, onError: () => {
}, onMessage: () => {
}, onModeChange: () => {
}, onStatusChange: () => {
}, onCanSendFeedbackChange: () => {
} };
var m = class _m {
  static async startSession(t2) {
    const n2 = e({}, p, h, t2);
    n2.onStatusChange({ status: "connecting" }), n2.onCanSendFeedbackChange({ canSendFeedback: false });
    let a2 = null, s2 = null, i2 = null;
    try {
      return s2 = await u.create(t2), [a2, i2] = await Promise.all([o.create(e({}, s2.inputFormat, { preferHeadphonesForIosDevices: t2.preferHeadphonesForIosDevices })), l.create(s2.outputFormat)]), new _m(n2, s2, a2, i2);
    } catch (e2) {
      var r2, c2, d2;
      throw n2.onStatusChange({ status: "disconnected" }), null == (r2 = s2) || r2.close(), await (null == (c2 = a2) ? void 0 : c2.close()), await (null == (d2 = i2) ? void 0 : d2.close()), e2;
    }
  }
  constructor(e2, a2, s2, o2) {
    var i2 = this;
    this.options = void 0, this.connection = void 0, this.input = void 0, this.output = void 0, this.lastInterruptTimestamp = 0, this.mode = "listening", this.status = "connecting", this.inputFrequencyData = void 0, this.outputFrequencyData = void 0, this.volume = 1, this.currentEventId = 1, this.lastFeedbackEventId = 1, this.canSendFeedback = false, this.endSession = async function() {
      "connected" === i2.status && (i2.updateStatus("disconnecting"), i2.connection.close(), await i2.input.close(), await i2.output.close(), i2.updateStatus("disconnected"));
    }, this.updateMode = (e3) => {
      e3 !== this.mode && (this.mode = e3, this.options.onModeChange({ mode: e3 }));
    }, this.updateStatus = (e3) => {
      e3 !== this.status && (this.status = e3, this.options.onStatusChange({ status: e3 }));
    }, this.updateCanSendFeedback = () => {
      const e3 = this.currentEventId !== this.lastFeedbackEventId;
      this.canSendFeedback !== e3 && (this.canSendFeedback = e3, this.options.onCanSendFeedbackChange({ canSendFeedback: e3 }));
    }, this.onEvent = async function(e3) {
      try {
        const n2 = JSON.parse(e3.data);
        if (!c(n2)) return;
        switch (n2.type) {
          case "interruption":
            n2.interruption_event && (i2.lastInterruptTimestamp = n2.interruption_event.event_id), i2.fadeOutAudio();
            break;
          case "agent_response":
            i2.options.onMessage({ source: "ai", message: n2.agent_response_event.agent_response });
            break;
          case "user_transcript":
            i2.options.onMessage({ source: "user", message: n2.user_transcription_event.user_transcript });
            break;
          case "internal_tentative_agent_response":
            i2.options.onDebug({ type: "tentative_agent_response", response: n2.tentative_agent_response_internal_event.tentative_agent_response });
            break;
          case "client_tool_call":
            if (i2.options.clientTools.hasOwnProperty(n2.client_tool_call.tool_name)) {
              try {
                var t2;
                const e4 = null != (t2 = await i2.options.clientTools[n2.client_tool_call.tool_name](n2.client_tool_call.parameters)) ? t2 : "Client tool execution successful.";
                i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: e4, is_error: false });
              } catch (e4) {
                i2.onError("Client tool execution failed with following error: " + (null == e4 ? void 0 : e4.message), { clientToolName: n2.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: "Client tool execution failed: " + (null == e4 ? void 0 : e4.message), is_error: true });
              }
              break;
            }
            if (i2.options.onUnhandledClientToolCall) {
              i2.options.onUnhandledClientToolCall(n2.client_tool_call);
              break;
            }
            i2.onError(`Client tool with name ${n2.client_tool_call.tool_name} is not defined on client`, { clientToolName: n2.client_tool_call.tool_name }), i2.connection.sendMessage({ type: "client_tool_result", tool_call_id: n2.client_tool_call.tool_call_id, result: `Client tool with name ${n2.client_tool_call.tool_name} is not defined on client`, is_error: true });
            break;
          case "audio":
            i2.lastInterruptTimestamp <= n2.audio_event.event_id && (i2.addAudioBase64Chunk(n2.audio_event.audio_base_64), i2.currentEventId = n2.audio_event.event_id, i2.updateCanSendFeedback(), i2.updateMode("speaking"));
            break;
          case "ping":
            i2.connection.sendMessage({ type: "pong", event_id: n2.ping_event.event_id });
            break;
          default:
            i2.options.onDebug(n2);
        }
      } catch (t3) {
        return void i2.onError("Failed to parse event data", { event: e3 });
      }
    }, this.onInputWorkletMessage = (e3) => {
      "connected" === this.status && this.connection.sendMessage({ user_audio_chunk: t(e3.data[0].buffer) });
    }, this.onOutputWorkletMessage = ({ data: e3 }) => {
      "process" === e3.type && this.updateMode(e3.finished ? "listening" : "speaking");
    }, this.addAudioBase64Chunk = async function(e3) {
      i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" }), i2.output.worklet.port.postMessage({ type: "buffer", buffer: n(e3) });
    }, this.fadeOutAudio = async function() {
      i2.updateMode("listening"), i2.output.worklet.port.postMessage({ type: "interrupt" }), i2.output.gain.gain.exponentialRampToValueAtTime(1e-4, i2.output.context.currentTime + 2), setTimeout(() => {
        i2.output.gain.gain.value = i2.volume, i2.output.worklet.port.postMessage({ type: "clearInterrupted" });
      }, 2e3);
    }, this.onError = (e3, t2) => {
      console.error(e3, t2), this.options.onError(e3, t2);
    }, this.calculateVolume = (e3) => {
      if (0 === e3.length) return 0;
      let t2 = 0;
      for (let n2 = 0; n2 < e3.length; n2++) t2 += e3[n2] / 255;
      return t2 /= e3.length, t2 < 0 ? 0 : t2 > 1 ? 1 : t2;
    }, this.getId = () => this.connection.conversationId, this.setVolume = ({ volume: e3 }) => {
      this.volume = e3;
    }, this.getInputByteFrequencyData = () => (null != this.inputFrequencyData || (this.inputFrequencyData = new Uint8Array(this.input.analyser.frequencyBinCount)), this.input.analyser.getByteFrequencyData(this.inputFrequencyData), this.inputFrequencyData), this.getOutputByteFrequencyData = () => (null != this.outputFrequencyData || (this.outputFrequencyData = new Uint8Array(this.output.analyser.frequencyBinCount)), this.output.analyser.getByteFrequencyData(this.outputFrequencyData), this.outputFrequencyData), this.getInputVolume = () => this.calculateVolume(this.getInputByteFrequencyData()), this.getOutputVolume = () => this.calculateVolume(this.getOutputByteFrequencyData()), this.sendFeedback = (e3) => {
      this.canSendFeedback ? (this.connection.sendMessage({ type: "feedback", score: e3 ? "like" : "dislike", event_id: this.currentEventId }), this.lastFeedbackEventId = this.currentEventId, this.updateCanSendFeedback()) : console.warn(0 === this.lastFeedbackEventId ? "Cannot send feedback: the conversation has not started yet." : "Cannot send feedback: feedback has already been sent for the current response.");
    }, this.options = e2, this.connection = a2, this.input = s2, this.output = o2, this.options.onConnect({ conversationId: a2.conversationId }), this.connection.socket.addEventListener("message", (e3) => {
      this.onEvent(e3);
    }), this.connection.socket.addEventListener("error", (e3) => {
      this.updateStatus("disconnected"), this.onError("Socket error", e3);
    }), this.connection.socket.addEventListener("close", () => {
      this.updateStatus("disconnected"), this.options.onDisconnect();
    }), this.input.worklet.port.onmessage = this.onInputWorkletMessage, this.output.worklet.port.onmessage = this.onOutputWorkletMessage, this.updateStatus("connected");
  }
};
function f(e2, t2, n2 = "https://api.elevenlabs.io") {
  return fetch(`${n2}/v1/convai/conversations/${e2}/feedback`, { method: "POST", body: JSON.stringify({ feedback: t2 ? "like" : "dislike" }), headers: { "Content-Type": "application/json" } });
}
export {
  m as Conversation,
  f as postOverallFeedback
};
//# sourceMappingURL=@11labs_client.js.map
